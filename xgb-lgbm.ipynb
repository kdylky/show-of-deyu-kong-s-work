{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-08-29T02:09:14.683146Z",
     "iopub.status.busy": "2025-08-29T02:09:14.682970Z",
     "iopub.status.idle": "2025-08-29T02:09:16.392961Z",
     "shell.execute_reply": "2025-08-29T02:09:16.392255Z",
     "shell.execute_reply.started": "2025-08-29T02:09:14.683129Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/playground-series-s5e8/sample_submission.csv\n",
      "/kaggle/input/playground-series-s5e8/train.csv\n",
      "/kaggle/input/playground-series-s5e8/test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-29T02:09:46.150117Z",
     "iopub.status.busy": "2025-08-29T02:09:46.149883Z",
     "iopub.status.idle": "2025-08-29T02:09:47.687206Z",
     "shell.execute_reply": "2025-08-29T02:09:47.686573Z",
     "shell.execute_reply.started": "2025-08-29T02:09:46.150098Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import polars as pl\n",
    "\n",
    "BASE = Path(\"/kaggle/input/playground-series-s5e8\")\n",
    "train, test, sub = (pl.read_csv(BASE / f) for f in (\"train.csv\", \"test.csv\", \"sample_submission.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-29T02:19:42.197183Z",
     "iopub.status.busy": "2025-08-29T02:19:42.196885Z",
     "iopub.status.idle": "2025-08-29T02:22:04.923751Z",
     "shell.execute_reply": "2025-08-29T02:22:04.922991Z",
     "shell.execute_reply.started": "2025-08-29T02:19:42.197164Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold] best_iter=2000  AUC=0.8598\n",
      "[Fold] best_iter=2000  AUC=0.8553\n",
      "[Fold] best_iter=2000  AUC=0.8550\n",
      "[Fold] best_iter=2000  AUC=0.8570\n",
      "[Fold] best_iter=2000  AUC=0.8544\n",
      "[OOF] AUC=0.8563 | F1@0.5=0.4713 | BestF1=0.5310 @thr=0.7031\n",
      "[Full] training with n_estimators=2000 (median of CV best iters)\n",
      "Saved -> submission_xgb_sota.csv\n",
      "       id         y\n",
      "0  750000  0.231733\n",
      "1  750001  0.349984\n",
      "2  750002  0.356784\n",
      "3  750003  0.001271\n",
      "4  750004  0.618832\n"
     ]
    }
   ],
   "source": [
    "# ===== XGBoost (Faster, Fixed) — CV + EarlyStopping(in constructor) + CPU/GPU auto =====\n",
    "from pathlib import Path\n",
    "import os, warnings, subprocess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, f1_score, precision_recall_curve\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import __version__ as sklearn_version\n",
    "from packaging import version\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "# ----------------------- Config -----------------------\n",
    "BASE = Path(\"/kaggle/input/playground-series-s5e8\")\n",
    "TARGET, ID = \"y\", \"id\"\n",
    "DROP_DURATION = True          # 现实部署建议 True（duration 有潜在泄漏）\n",
    "FOLDS = 5\n",
    "SEED = 42\n",
    "EARLY_STOP = 200\n",
    "VERBOSE = False\n",
    "\n",
    "# —— 极速模式（可能略降分；提速明显）——\n",
    "ULTRA_FAST = False\n",
    "\n",
    "# 外层并行（多核时 2 折并行较稳；核少时自动关）\n",
    "CPU = os.cpu_count() or 8\n",
    "OUTER_JOBS = 2 if CPU >= 16 else 1\n",
    "INNER_JOBS = max(1, CPU // OUTER_JOBS)\n",
    "\n",
    "# ----------------------- 环境/版本探测 -----------------------\n",
    "def has_gpu() -> bool:\n",
    "    try:\n",
    "        out = subprocess.run([\"nvidia-smi\", \"-L\"], capture_output=True, text=True)\n",
    "        return out.returncode == 0 and \"GPU\" in out.stdout\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "XGB_VER = version.parse(xgb.__version__)\n",
    "HAS_GPU = has_gpu()\n",
    "\n",
    "# XGBoost 2.0+：用 device；老版本：用 tree_method\n",
    "if XGB_VER >= version.parse(\"2.0.0\"):\n",
    "    DEVICE_KW = dict(tree_method=\"hist\", device=(\"cuda\" if HAS_GPU else \"cpu\"))\n",
    "else:\n",
    "    DEVICE_KW = dict(tree_method=(\"gpu_hist\" if HAS_GPU else \"hist\"))\n",
    "\n",
    "# sklearn 1.2+ 的 OneHotEncoder 使用 sparse_output\n",
    "HAS_SPARSE_OUTPUT = version.parse(sklearn_version) >= version.parse(\"1.2\")\n",
    "\n",
    "# XGB 原生类别支持（1.6+）\n",
    "HAS_NATIVE_CAT = XGB_VER >= version.parse(\"1.6.0\")\n",
    "\n",
    "# ----------------------- Load -------------------------\n",
    "train_pl = pl.read_csv(BASE / \"train.csv\")\n",
    "test_pl  = pl.read_csv(BASE / \"test.csv\")\n",
    "sub      = pd.read_csv(BASE / \"sample_submission.csv\")\n",
    "\n",
    "if DROP_DURATION and \"duration\" in train_pl.columns:\n",
    "    train_pl = train_pl.drop(\"duration\")\n",
    "    if \"duration\" in test_pl.columns:\n",
    "        test_pl = test_pl.drop(\"duration\")\n",
    "\n",
    "train = train_pl.to_pandas()\n",
    "test  = test_pl.to_pandas()\n",
    "\n",
    "y = train[TARGET].astype(int).values\n",
    "X = train.drop(columns=[TARGET, ID])\n",
    "X_test = test.drop(columns=[ID], errors=\"ignore\")\n",
    "\n",
    "# ----------------------- 轻量特征工程 & 同步到测试集 -----------------------\n",
    "# 1) pdays：-1 表示从未联系过\n",
    "if \"pdays\" in X.columns:\n",
    "    X[\"was_prev_contacted\"] = (X[\"pdays\"] != -1).astype(np.int8)\n",
    "    X_test[\"was_prev_contacted\"] = (X_test[\"pdays\"] != -1).astype(np.int8)\n",
    "    X[\"pdays_pos\"] = X[\"pdays\"].where(X[\"pdays\"] >= 0, other=np.nan)\n",
    "    X_test[\"pdays_pos\"] = X_test[\"pdays\"].where(X_test[\"pdays\"] >= 0, other=np.nan)\n",
    "\n",
    "# 2) month 周期（同步创建到测试集）\n",
    "month_map = {\"jan\":1,\"feb\":2,\"mar\":3,\"apr\":4,\"may\":5,\"jun\":6,\n",
    "             \"jul\":7,\"aug\":8,\"sep\":9,\"oct\":10,\"nov\":11,\"dec\":12}\n",
    "if \"month\" in X.columns:\n",
    "    X[\"month_num\"] = pd.Series(X[\"month\"]).map(month_map).fillna(0).astype(int)\n",
    "    X_test[\"month_num\"] = pd.Series(X_test[\"month\"]).map(month_map).fillna(0).astype(int)\n",
    "    X[\"month_sin\"] = np.sin(2*np.pi*X[\"month_num\"]/12)\n",
    "    X[\"month_cos\"] = np.cos(2*np.pi*X[\"month_num\"]/12)\n",
    "    X_test[\"month_sin\"] = np.sin(2*np.pi*X_test[\"month_num\"]/12)\n",
    "    X_test[\"month_cos\"] = np.cos(2*np.pi*X_test[\"month_num\"]/12)\n",
    "\n",
    "# 3) 温和去极值\n",
    "for col in [\"balance\", \"campaign\", \"previous\"]:\n",
    "    if col in X.columns:\n",
    "        lo, hi = X[col].quantile([0.001, 0.999])\n",
    "        X[col] = X[col].clip(lo, hi)\n",
    "        if col in X_test.columns:\n",
    "            X_test[col] = X_test[col].clip(lo, hi)\n",
    "\n",
    "# —— 统一降精度（先对齐列，防止测试集缺列报 KeyError）——\n",
    "for c in X.columns:\n",
    "    if c not in X_test.columns:\n",
    "        X_test[c] = np.nan\n",
    "\n",
    "for c in X.columns:\n",
    "    if str(X[c].dtype) == \"category\":\n",
    "        continue\n",
    "    if pd.api.types.is_integer_dtype(X[c]):\n",
    "        X[c] = X[c].astype(np.int32)\n",
    "        X_test[c] = X_test[c].astype(np.int32, errors=\"ignore\")\n",
    "    elif pd.api.types.is_float_dtype(X[c]) or pd.api.types.is_bool_dtype(X[c]):\n",
    "        X[c] = X[c].astype(np.float32)\n",
    "        X_test[c] = X_test[c].astype(np.float32, errors=\"ignore\")\n",
    "\n",
    "# —— 将 object 转为 category（原生类别更快/更省内存；One-Hot 也可用）——\n",
    "for c in X.columns:\n",
    "    if X[c].dtype == \"object\":\n",
    "        X[c] = X[c].astype(\"category\")\n",
    "for c in X.columns:\n",
    "    if str(X[c].dtype) == \"category\" and c in X_test.columns:\n",
    "        X_test[c] = X_test[c].astype(\"category\")\n",
    "\n",
    "# 最终对齐列顺序\n",
    "X_test = X_test.reindex(columns=X.columns)\n",
    "\n",
    "# 列分组\n",
    "def is_cat(s: pd.Series) -> bool:\n",
    "    return (s.dtype == \"object\") or (str(s.dtype) == \"category\")\n",
    "cat_cols = [c for c in X.columns if is_cat(X[c])]\n",
    "num_cols = [c for c in X.columns if c not in cat_cols]\n",
    "\n",
    "# ----------------------- Params -----------------------\n",
    "pos = y.sum(); neg = len(y) - pos\n",
    "scale_pos_weight = neg / max(1, pos)\n",
    "\n",
    "base_params = dict(\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"auc\",\n",
    "    learning_rate=0.03,\n",
    "    n_estimators=2000,            # 会被 early stopping 截断\n",
    "    max_depth=6,\n",
    "    min_child_weight=4,\n",
    "    subsample=0.85,\n",
    "    colsample_bytree=0.85,\n",
    "    colsample_bynode=0.85,\n",
    "    reg_alpha=0.0,\n",
    "    reg_lambda=1.0,\n",
    "    max_bin=512,\n",
    "    random_state=SEED,\n",
    "    n_jobs=INNER_JOBS,            # 外层并行时限制内层线程数\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    early_stopping_rounds=EARLY_STOP,   # 在构造器里传\n",
    "    **DEVICE_KW,                        # 正确设定 CPU/GPU\n",
    ")\n",
    "\n",
    "# 更快的直方图设置（基本不掉分）\n",
    "base_params.update(dict(\n",
    "    max_bin=256,\n",
    "    colsample_bytree=0.75,\n",
    "    colsample_bynode=0.75,\n",
    "    subsample=0.80,\n",
    "    min_child_weight=6,\n",
    "))\n",
    "if XGB_VER >= version.parse(\"1.6.0\"):\n",
    "    base_params[\"sampling_method\"] = \"gradient_based\"\n",
    "\n",
    "# ✅ 仅对 XGBoost < 2.0 且有 GPU 时设置 predictor，避免 2.x 的“unused parameter”警告\n",
    "if XGB_VER < version.parse(\"2.0.0\") and HAS_GPU:\n",
    "    base_params[\"predictor\"] = \"gpu_predictor\"\n",
    "\n",
    "# 极速模式（可能略降分）\n",
    "if ULTRA_FAST:\n",
    "    FOLDS = 3\n",
    "    EARLY_STOP = 100\n",
    "    base_params.update(dict(\n",
    "        learning_rate=0.05,\n",
    "        max_depth=5,\n",
    "        min_child_weight=8,\n",
    "        subsample=0.75,\n",
    "        colsample_bytree=0.70,\n",
    "        colsample_bynode=0.70,\n",
    "        n_estimators=1500,\n",
    "        max_bin=256,\n",
    "    ))\n",
    "    base_params[\"early_stopping_rounds\"] = EARLY_STOP\n",
    "\n",
    "# ----------------------- Encoders (One-Hot fallback prefit) -----------------------\n",
    "pre = None\n",
    "if not HAS_NATIVE_CAT and len(cat_cols) > 0:\n",
    "    if HAS_SPARSE_OUTPUT:\n",
    "        ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=True, dtype=np.float32)\n",
    "    else:\n",
    "        ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse=True, dtype=np.float32)\n",
    "    pre = ColumnTransformer([(\"cat\", ohe, cat_cols)], remainder=\"passthrough\")\n",
    "    pre.fit(X)  # 预先全量拟合（不依赖 y），各折复用\n",
    "\n",
    "# ----------------------- Helpers -----------------------\n",
    "skf = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=SEED)\n",
    "\n",
    "def best_iter_of(model: xgb.XGBClassifier) -> int:\n",
    "    if hasattr(model, \"best_iteration_\") and model.best_iteration_ is not None:\n",
    "        return int(model.best_iteration_)\n",
    "    try:\n",
    "        return int(model.get_booster().best_ntree_limit)\n",
    "    except Exception:\n",
    "        return int(getattr(model, \"n_estimators\", 2000))\n",
    "\n",
    "def run_fold(tr_idx, va_idx):\n",
    "    if HAS_NATIVE_CAT:\n",
    "        params = base_params | dict(enable_categorical=True)\n",
    "        model = xgb.XGBClassifier(**params)\n",
    "        model.fit(X.iloc[tr_idx], y[tr_idx], eval_set=[(X.iloc[va_idx], y[va_idx])], verbose=VERBOSE)\n",
    "        proba_va = model.predict_proba(X.iloc[va_idx])[:, 1]\n",
    "    else:\n",
    "        Xtr = pre.transform(X.iloc[tr_idx]) if pre is not None else X.iloc[tr_idx]\n",
    "        Xva = pre.transform(X.iloc[va_idx]) if pre is not None else X.iloc[va_idx]\n",
    "        model = xgb.XGBClassifier(**base_params)\n",
    "        model.fit(Xtr, y[tr_idx], eval_set=[(Xva, y[va_idx])], verbose=VERBOSE)\n",
    "        proba_va = model.predict_proba(Xva)[:, 1]\n",
    "    return va_idx, proba_va, model\n",
    "\n",
    "# ----------------------- OOF CV（可外层并行） -----------------------\n",
    "folds = list(skf.split(X, y))\n",
    "if OUTER_JOBS > 1:\n",
    "    results = Parallel(n_jobs=OUTER_JOBS, prefer=\"threads\")(delayed(run_fold)(tr, va) for tr, va in folds)\n",
    "else:\n",
    "    results = [run_fold(tr, va) for tr, va in folds]\n",
    "\n",
    "oof = np.zeros(len(y), dtype=float)\n",
    "best_iters = []\n",
    "for va_idx, proba_va, model in results:\n",
    "    oof[va_idx] = proba_va\n",
    "    bi = best_iter_of(model)\n",
    "    best_iters.append(bi)\n",
    "    print(f\"[Fold] best_iter={bi}  AUC={roc_auc_score(y[va_idx], oof[va_idx]):.4f}\")\n",
    "\n",
    "auc = roc_auc_score(y, oof)\n",
    "f1_05 = f1_score(y, (oof >= 0.5).astype(int))\n",
    "prec, rec, thr = precision_recall_curve(y, oof)\n",
    "f1s = 2 * prec[:-1] * rec[:-1] / (prec[:-1] + rec[:-1] + 1e-12)\n",
    "best_ix = int(np.nanargmax(f1s))\n",
    "best_thr = float(thr[best_ix])\n",
    "print(f\"[OOF] AUC={auc:.4f} | F1@0.5={f1_05:.4f} | BestF1={f1s[best_ix]:.4f} @thr={best_thr:.4f}\")\n",
    "\n",
    "# ----------------------- Full fit with tuned n_estimators -----------------------\n",
    "best_round = max(100, int(np.median(best_iters)))\n",
    "print(f\"[Full] training with n_estimators={best_round} (median of CV best iters)\")\n",
    "\n",
    "if HAS_NATIVE_CAT:\n",
    "    params_full = base_params | dict(enable_categorical=True, n_estimators=best_round)\n",
    "    final = xgb.XGBClassifier(**params_full)\n",
    "    # 用随机 5% 作为早停验证（更快；若不稳定可改回 10%）\n",
    "    rng = np.random.RandomState(SEED)\n",
    "    idx = rng.permutation(len(X))\n",
    "    cut = int(0.95 * len(X))\n",
    "    tr_idx, va_idx = idx[:cut], idx[cut:]\n",
    "    final.fit(X.iloc[tr_idx], y[tr_idx], eval_set=[(X.iloc[va_idx], y[va_idx])], verbose=VERBOSE)\n",
    "    test_proba = final.predict_proba(X_test)[:, 1]\n",
    "else:\n",
    "    if pre is None:\n",
    "        Xt_all, Xt_tst = X, X_test\n",
    "    else:\n",
    "        Xt_all = pre.transform(X)\n",
    "        Xt_tst = pre.transform(X_test)\n",
    "    params_full = base_params | dict(n_estimators=best_round)\n",
    "    final = xgb.XGBClassifier(**params_full)\n",
    "\n",
    "    rng = np.random.RandomState(SEED)\n",
    "    idx = rng.permutation(len(X))\n",
    "    cut = int(0.95 * len(X))\n",
    "    tr_idx, va_idx = idx[:cut], idx[cut:]\n",
    "\n",
    "    X_tr, y_tr = Xt_all[tr_idx], y[tr_idx]\n",
    "    X_va, y_va = Xt_all[va_idx], y[va_idx]\n",
    "    final.fit(X_tr, y_tr, eval_set=[(X_va, y_va)], verbose=VERBOSE)\n",
    "    test_proba = final.predict_proba(Xt_tst)[:, 1]\n",
    "\n",
    "# ----------------------- Submit -----------------------\n",
    "out = sub.copy()\n",
    "out[\"y\"] = test_proba\n",
    "out.to_csv(\"submission_xgb_sota.csv\", index=False)\n",
    "print(\"Saved -> submission_xgb_sota.csv\")\n",
    "print(out.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-29T02:27:05.549913Z",
     "iopub.status.busy": "2025-08-29T02:27:05.549354Z",
     "iopub.status.idle": "2025-08-29T02:34:49.234097Z",
     "shell.execute_reply": "2025-08-29T02:34:49.233403Z",
     "shell.execute_reply.started": "2025-08-29T02:27:05.549888Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold] best_iter=1925  AUC=0.8605\n",
      "[Fold] best_iter=1535  AUC=0.8566\n",
      "[Fold] best_iter=1229  AUC=0.8563\n",
      "[Fold] best_iter=1827  AUC=0.8579\n",
      "[Fold] best_iter=1363  AUC=0.8558\n",
      "[OOF] AUC=0.8574 | F1@0.5=0.4749 | BestF1=0.5328 @thr=0.6971\n",
      "[Full] training with n_estimators=1535 (median of CV best iters)\n",
      "Saved -> submission_lgbm_sota.csv\n",
      "       id         y\n",
      "0  750000  0.216924\n",
      "1  750001  0.334075\n",
      "2  750002  0.348150\n",
      "3  750003  0.002067\n",
      "4  750004  0.659697\n"
     ]
    }
   ],
   "source": [
    "# ===== LightGBM (Fast, Fixed) — CV + EarlyStopping + CPU/GPU auto =====\n",
    "from pathlib import Path\n",
    "import os, warnings, subprocess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, f1_score, precision_recall_curve\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import lightgbm as lgb\n",
    "from packaging import version\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ----------------------- Config -----------------------\n",
    "BASE = Path(\"/kaggle/input/playground-series-s5e8\")\n",
    "TARGET, ID = \"y\", \"id\"\n",
    "DROP_DURATION = True          # 现实部署建议 True（duration 有潜在泄漏）\n",
    "FOLDS = 5\n",
    "SEED = 42\n",
    "EARLY_STOP = 200\n",
    "VERBOSE = False               # 控制训练日志\n",
    "\n",
    "# —— 极速模式（可能略降分；提速明显）——\n",
    "ULTRA_FAST = False\n",
    "\n",
    "# 外层并行（多核时 2 折并行较稳；核少时自动关）\n",
    "CPU = os.cpu_count() or 8\n",
    "OUTER_JOBS = 2 if CPU >= 16 else 1\n",
    "INNER_JOBS = max(1, CPU // OUTER_JOBS)\n",
    "\n",
    "# ----------------------- 环境/版本探测 -----------------------\n",
    "def has_gpu() -> bool:\n",
    "    try:\n",
    "        out = subprocess.run([\"nvidia-smi\", \"-L\"], capture_output=True, text=True)\n",
    "        return out.returncode == 0 and \"GPU\" in out.stdout\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "HAS_GPU = has_gpu()\n",
    "LGB_VER = version.parse(lgb.__version__)\n",
    "\n",
    "# LightGBM 设备参数\n",
    "DEVICE_KW = dict(device_type=(\"gpu\" if HAS_GPU else \"cpu\"))\n",
    "\n",
    "# ----------------------- Load -------------------------\n",
    "train_pl = pl.read_csv(BASE / \"train.csv\")\n",
    "test_pl  = pl.read_csv(BASE / \"test.csv\")\n",
    "sub      = pd.read_csv(BASE / \"sample_submission.csv\")\n",
    "\n",
    "if DROP_DURATION and \"duration\" in train_pl.columns:\n",
    "    train_pl = train_pl.drop(\"duration\")\n",
    "    if \"duration\" in test_pl.columns:\n",
    "        test_pl = test_pl.drop(\"duration\")\n",
    "\n",
    "train = train_pl.to_pandas()\n",
    "test  = test_pl.to_pandas()\n",
    "\n",
    "y = train[TARGET].astype(int).values\n",
    "X = train.drop(columns=[TARGET, ID])\n",
    "X_test = test.drop(columns=[ID], errors=\"ignore\")\n",
    "\n",
    "# ----------------------- 轻量特征工程 & 同步到测试集 -----------------------\n",
    "# 1) pdays：-1 表示从未联系过\n",
    "if \"pdays\" in X.columns:\n",
    "    X[\"was_prev_contacted\"] = (X[\"pdays\"] != -1).astype(np.int8)\n",
    "    X_test[\"was_prev_contacted\"] = (X_test[\"pdays\"] != -1).astype(np.int8)\n",
    "    X[\"pdays_pos\"] = X[\"pdays\"].where(X[\"pdays\"] >= 0, other=np.nan)\n",
    "    X_test[\"pdays_pos\"] = X_test[\"pdays\"].where(X_test[\"pdays\"] >= 0, other=np.nan)\n",
    "\n",
    "# 2) month 周期\n",
    "month_map = {\"jan\":1,\"feb\":2,\"mar\":3,\"apr\":4,\"may\":5,\"jun\":6,\n",
    "             \"jul\":7,\"aug\":8,\"sep\":9,\"oct\":10,\"nov\":11,\"dec\":12}\n",
    "if \"month\" in X.columns:\n",
    "    X[\"month_num\"] = pd.Series(X[\"month\"]).map(month_map).fillna(0).astype(int)\n",
    "    X_test[\"month_num\"] = pd.Series(X_test[\"month\"]).map(month_map).fillna(0).astype(int)\n",
    "    X[\"month_sin\"] = np.sin(2*np.pi*X[\"month_num\"]/12)\n",
    "    X[\"month_cos\"] = np.cos(2*np.pi*X[\"month_num\"]/12)\n",
    "    X_test[\"month_sin\"] = np.sin(2*np.pi*X_test[\"month_num\"]/12)\n",
    "    X_test[\"month_cos\"] = np.cos(2*np.pi*X_test[\"month_num\"]/12)\n",
    "\n",
    "# 3) 温和去极值\n",
    "for col in [\"balance\", \"campaign\", \"previous\"]:\n",
    "    if col in X.columns:\n",
    "        lo, hi = X[col].quantile([0.001, 0.999])\n",
    "        X[col] = X[col].clip(lo, hi)\n",
    "        if col in X_test.columns:\n",
    "            X_test[col] = X_test[col].clip(lo, hi)\n",
    "\n",
    "# —— 统一降精度（先对齐列，防止测试集缺列报错）——\n",
    "for c in X.columns:\n",
    "    if c not in X_test.columns:\n",
    "        X_test[c] = np.nan\n",
    "\n",
    "for c in X.columns:\n",
    "    if str(X[c].dtype) == \"category\":\n",
    "        continue\n",
    "    if pd.api.types.is_integer_dtype(X[c]):\n",
    "        X[c] = X[c].astype(np.int32)\n",
    "        X_test[c] = X_test[c].astype(np.int32, errors=\"ignore\")\n",
    "    elif pd.api.types.is_float_dtype(X[c]) or pd.api.types.is_bool_dtype(X[c]):\n",
    "        X[c] = X[c].astype(np.float32)\n",
    "        X_test[c] = X_test[c].astype(np.float32, errors=\"ignore\")\n",
    "\n",
    "# —— 将 object 转为 category（LightGBM 原生类别支持，速度/内存友好）——\n",
    "for c in X.columns:\n",
    "    if X[c].dtype == \"object\":\n",
    "        X[c] = X[c].astype(\"category\")\n",
    "for c in X.columns:\n",
    "    if str(X[c].dtype) == \"category\" and c in X_test.columns:\n",
    "        X_test[c] = X_test[c].astype(\"category\")\n",
    "\n",
    "# 最终对齐列顺序\n",
    "X_test = X_test.reindex(columns=X.columns)\n",
    "\n",
    "# 类别列/数值列\n",
    "def is_cat(s: pd.Series) -> bool:\n",
    "    return (s.dtype == \"object\") or (str(s.dtype) == \"category\")\n",
    "\n",
    "cat_cols = [c for c in X.columns if is_cat(X[c])]\n",
    "num_cols = [c for c in X.columns if c not in cat_cols]\n",
    "\n",
    "# ----------------------- Params -----------------------\n",
    "pos = y.sum(); neg = len(y) - pos\n",
    "scale_pos_weight = neg / max(1, pos)\n",
    "\n",
    "base_params = dict(\n",
    "    objective=\"binary\",\n",
    "    metric=\"auc\",\n",
    "    learning_rate=0.03,\n",
    "    n_estimators=2000,            # 会被 early stopping 截断\n",
    "    num_leaves=63,                # ~ 2^6-1（对应 max_depth≈6）\n",
    "    max_depth=-1,                 # 由 num_leaves 控制复杂度\n",
    "    min_data_in_leaf=40,\n",
    "    feature_fraction=0.85,\n",
    "    bagging_fraction=0.85,\n",
    "    bagging_freq=1,\n",
    "    lambda_l1=0.0,\n",
    "    lambda_l2=1.0,\n",
    "    max_bin=255,\n",
    "    random_state=SEED,\n",
    "    n_jobs=INNER_JOBS,            # ✅ 外层并行时限制内层线程数，避免超订\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    force_col_wise=True,          # ✅ CPU 上更稳更省内存\n",
    "    **DEVICE_KW,                  # ✅ 正确设定 CPU/GPU\n",
    "    verbosity=-1,\n",
    ")\n",
    "\n",
    "# 稍更“竞赛友好”的直方图/抽样设置（速度与稳健折中）\n",
    "base_params.update(dict(\n",
    "    feature_fraction=0.75,\n",
    "    bagging_fraction=0.80,\n",
    "    min_data_in_leaf=60,\n",
    "))\n",
    "\n",
    "# 极速模式（可能略降分）\n",
    "if ULTRA_FAST:\n",
    "    FOLDS = 3\n",
    "    EARLY_STOP = 100\n",
    "    base_params.update(dict(\n",
    "        learning_rate=0.05,\n",
    "        num_leaves=48,\n",
    "        min_data_in_leaf=80,\n",
    "        feature_fraction=0.70,\n",
    "        bagging_fraction=0.75,\n",
    "        n_estimators=1500,\n",
    "        max_bin=255,\n",
    "    ))\n",
    "\n",
    "# ----------------------- Helpers -----------------------\n",
    "skf = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=SEED)\n",
    "\n",
    "def best_iter_of(model: lgb.LGBMClassifier) -> int:\n",
    "    bi = getattr(model, \"best_iteration_\", None)\n",
    "    if bi is not None and bi > 0:\n",
    "        return int(bi)\n",
    "    return int(getattr(model, \"n_estimators\", 2000))\n",
    "\n",
    "def fit_with_es(model, X_tr, y_tr, X_va, y_va, cat_cols, early_stopping_rounds, verbose):\n",
    "    \"\"\"兼容不同 LightGBM 版本的早停写法（优先用 callbacks）。\"\"\"\n",
    "    try:\n",
    "        # 新写法：callbacks\n",
    "        return model.fit(\n",
    "            X_tr, y_tr,\n",
    "            eval_set=[(X_va, y_va)],\n",
    "            eval_metric=\"auc\",\n",
    "            categorical_feature=cat_cols if len(cat_cols) > 0 else \"auto\",\n",
    "            callbacks=[\n",
    "                lgb.early_stopping(early_stopping_rounds, verbose=verbose),\n",
    "                lgb.log_evaluation(period=50 if verbose else 0),\n",
    "            ]\n",
    "        )\n",
    "    except TypeError:\n",
    "        # 旧版本兜底\n",
    "        return model.fit(\n",
    "            X_tr, y_tr,\n",
    "            eval_set=[(X_va, y_va)],\n",
    "            eval_metric=\"auc\",\n",
    "            categorical_feature=cat_cols if len(cat_cols) > 0 else \"auto\",\n",
    "            early_stopping_rounds=early_stopping_rounds,\n",
    "            verbose=verbose\n",
    "        )\n",
    "\n",
    "def run_fold(tr_idx, va_idx):\n",
    "    model = lgb.LGBMClassifier(**base_params)\n",
    "    model = fit_with_es(model,\n",
    "                        X.iloc[tr_idx], y[tr_idx],\n",
    "                        X.iloc[va_idx], y[va_idx],\n",
    "                        cat_cols=cat_cols,\n",
    "                        early_stopping_rounds=EARLY_STOP,\n",
    "                        verbose=VERBOSE)\n",
    "    proba_va = model.predict_proba(X.iloc[va_idx])[:, 1]\n",
    "    return va_idx, proba_va, model\n",
    "\n",
    "# ----------------------- OOF CV（可外层并行） -----------------------\n",
    "folds = list(skf.split(X, y))\n",
    "if OUTER_JOBS > 1:\n",
    "    results = Parallel(n_jobs=OUTER_JOBS, prefer=\"threads\")(delayed(run_fold)(tr, va) for tr, va in folds)\n",
    "else:\n",
    "    results = [run_fold(tr, va) for tr, va in folds]\n",
    "\n",
    "oof = np.zeros(len(y), dtype=float)\n",
    "best_iters = []\n",
    "for va_idx, proba_va, model in results:\n",
    "    oof[va_idx] = proba_va\n",
    "    bi = best_iter_of(model)\n",
    "    best_iters.append(bi)\n",
    "    print(f\"[Fold] best_iter={bi}  AUC={roc_auc_score(y[va_idx], oof[va_idx]):.4f}\")\n",
    "\n",
    "auc = roc_auc_score(y, oof)\n",
    "f1_05 = f1_score(y, (oof >= 0.5).astype(int))\n",
    "prec, rec, thr = precision_recall_curve(y, oof)\n",
    "f1s = 2 * prec[:-1] * rec[:-1] / (prec[:-1] + rec[:-1] + 1e-12)\n",
    "best_ix = int(np.nanargmax(f1s))\n",
    "best_thr = float(thr[best_ix])\n",
    "print(f\"[OOF] AUC={auc:.4f} | F1@0.5={f1_05:.4f} | BestF1={f1s[best_ix]:.4f} @thr={best_thr:.4f}\")\n",
    "\n",
    "# ----------------------- Full fit with tuned n_estimators -----------------------\n",
    "best_round = max(100, int(np.median(best_iters)))\n",
    "print(f\"[Full] training with n_estimators={best_round} (median of CV best iters)\")\n",
    "\n",
    "params_full = dict(base_params)\n",
    "params_full[\"n_estimators\"] = best_round\n",
    "\n",
    "final = lgb.LGBMClassifier(**params_full)\n",
    "\n",
    "# 用随机 5% 作为早停验证（更快；若不稳定可改 10%）\n",
    "rng = np.random.RandomState(SEED)\n",
    "idx = rng.permutation(len(X))\n",
    "cut = int(0.95 * len(X))\n",
    "tr_idx, va_idx = idx[:cut], idx[cut:]\n",
    "\n",
    "final = fit_with_es(final,\n",
    "                    X.iloc[tr_idx], y[tr_idx],\n",
    "                    X.iloc[va_idx], y[va_idx],\n",
    "                    cat_cols=cat_cols,\n",
    "                    early_stopping_rounds=EARLY_STOP,\n",
    "                    verbose=VERBOSE)\n",
    "\n",
    "test_proba = final.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# ----------------------- Submit -----------------------\n",
    "out = sub.copy()\n",
    "out[\"y\"] = test_proba\n",
    "out.to_csv(\"submission_lgbm_sota.csv\", index=False)\n",
    "print(\"Saved -> submission_lgbm_sota.csv\")\n",
    "print(out.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 12937777,
     "sourceId": 91719,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
